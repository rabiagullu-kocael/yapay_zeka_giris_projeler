{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0478a3d5",
   "metadata": {},
   "source": [
    "Fine-Tuning (Full Fine-Tuning) Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Önceden eğitilmiş bir modeli yüklüyoruz\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Küçük bir örnek veri seti (demo amaçlı)\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Eğitim parametreleri\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "# Trainer tüm model parametrelerini güncelleyecek (Full Fine-Tuning)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219e427",
   "metadata": {},
   "source": [
    "Bu örnekte modelin tüm parametreleri güncellenir. Yüksek performans sağlar ancak GPU belleği ve süre maliyeti yüksektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b997ba",
   "metadata": {},
   "source": [
    "Feature Extraction Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f819f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False  # Modelin gövdesini donduruyoruz\n",
    "\n",
    "# Sadece classification head eğitilir\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47deac78",
   "metadata": {},
   "source": [
    "Burada modelin ana katmanları sabit kalır, yalnızca son katman eğitilir.\n",
    "Daha düşük maliyetlidir ancak esneklik sınırlıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca76977",
   "metadata": {},
   "source": [
    "PEFT Tanımı – LoRA Kullanımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# LoRA konfigürasyonu\n",
    "config = LoraConfig(\n",
    "    r=8,                      # low-rank matris boyutu\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\"], # hangi katmanlara uygulanacağı\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# Modeli PEFT ile sarıyoruz\n",
    "peft_model = get_peft_model(model, config)\n",
    "\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd0076",
   "metadata": {},
   "source": [
    "Bu kod yalnızca küçük LoRA matrislerini eğitilebilir yapar.\n",
    "Ana model sabit kalır → GPU tasarrufu sağlanır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f44938",
   "metadata": {},
   "source": [
    "Prefix Tuning Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec67e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PrefixTuningConfig, get_peft_model\n",
    "\n",
    "config = PrefixTuningConfig(\n",
    "    num_virtual_tokens=20  # modele eklenecek öğrenilebilir prefix sayısı\n",
    ")\n",
    "\n",
    "prefix_model = get_peft_model(model, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c18e33",
   "metadata": {},
   "source": [
    "Model parametreleri değiştirilmez.\n",
    "Sadece girişe eklenen öğrenilebilir prefix vektörleri eğitilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890975d1",
   "metadata": {},
   "source": [
    "Adapter Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82856094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AdapterConfig\n",
    "\n",
    "config = AdapterConfig(\n",
    "    reduction_factor=16  # adapter katmanının küçültme oranı\n",
    ")\n",
    "\n",
    "adapter_model = get_peft_model(model, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4220b01a",
   "metadata": {},
   "source": [
    "Transformer katmanları arasına küçük adapter modülleri eklenir.\n",
    "Yalnızca bu küçük modüller eğitilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb28959",
   "metadata": {},
   "source": [
    "BitFit Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        param.requires_grad = True   # sadece bias parametreleri eğitilir\n",
    "    else:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0e580",
   "metadata": {},
   "source": [
    "Modelin yalnızca bias terimleri güncellenir.\n",
    "En düşük maliyetli fakat sınırlı adaptasyon sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92bba1",
   "metadata": {},
   "source": [
    "RAG (Retrieval-Augmented Generation) Mini Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Metinleri embedding'e çevirip vektör veritabanına koyuyoruz\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"LLM nedir?\", \"Transformer mimarisi self-attention kullanır.\"],\n",
    "    OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "# Retriever oluşturuyoruz\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# LLM + Retriever zinciri\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "response = qa.run(\"Transformer nasıl çalışır?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5353a2c",
   "metadata": {},
   "source": [
    "Model cevap üretmeden önce ilgili dokümanları çağırır.\n",
    "Bilgi parametrelerden değil, harici kaynaktan gelir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386aca5",
   "metadata": {},
   "source": [
    "Haystack ile RAG Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c336cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Dokümanları indexler\n",
    "document_store.update_embeddings(retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615aaa85",
   "metadata": {},
   "source": [
    "Haystack özellikle doküman arama ve QA sistemleri için optimize edilmiştir.\n",
    "Endüstriyel RAG projelerinde sık kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe32d0",
   "metadata": {},
   "source": [
    "VQA ve Image Captioning Mini Örnek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9696325",
   "metadata": {},
   "source": [
    "Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff69f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "processor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "image = Image.open(\"example.jpg\")\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "output_ids = model.generate(pixel_values)\n",
    "caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5102be",
   "metadata": {},
   "source": [
    "Görsel → metin üretir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e1075",
   "metadata": {},
   "source": [
    "VQA Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
    "\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "\n",
    "encoding = processor(image, \"Bu görselde kaç kişi var?\", return_tensors=\"pt\")\n",
    "outputs = model(**encoding)\n",
    "\n",
    "logits = outputs.logits\n",
    "predicted_answer = logits.argmax(-1)\n",
    "\n",
    "print(predicted_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6819e56",
   "metadata": {},
   "source": [
    "Görsel + soru → cevap üretir.\n",
    "RAG ile entegre edilirse harici bilgi de eklenebilir."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
